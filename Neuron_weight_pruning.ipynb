{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "### Loading the mnist data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "###Normalising the training and testing data\n",
    "x_train = x_train / 255.0 \n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "###Flattening the training features\n",
    "x_train_flat = tf.contrib.layers.flatten(x_train)\n",
    "###Converting labels into one hot encoding\n",
    "y_train_onehot = tf.one_hot(y_train, depth = 10)\n",
    "sess = tf.Session()\n",
    "y_train_onehot = y_train_onehot.eval(session=sess)\n",
    "x_train_flat = x_train_flat.eval(session=sess)\n",
    "q = y_train_onehot.shape[1]\n",
    "m = x_train_flat.shape[1]\n",
    "\n",
    "###Repeating same procedure for the test data\n",
    "x_test_flat = tf.contrib.layers.flatten(x_test)\n",
    "y_test_onehot = tf.one_hot(y_test, depth = 10)\n",
    "sess = tf.Session()\n",
    "y_test_onehot = y_test_onehot.eval(session=sess)\n",
    "x_test_flat = x_test_flat.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating the placeholders for features and labels\n",
    "x = tf.placeholder(tf.float32,[None, m])\n",
    "y = tf.placeholder(tf.float32,[None, q])\n",
    "y_onehot = tf.argmax(y, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "layer1 = 1000\n",
    "layer2 = 1000\n",
    "layer3 = 500\n",
    "layer4 = 200\n",
    "###Intialize the weight variable and calculating the hypothesis\n",
    "w1 = tf.Variable(tf.random.truncated_normal([m,layer1], stddev = 0.05))\n",
    "hyp1 = tf.nn.relu(tf.matmul(x,w1))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([layer1,layer2],stddev = 0.05))\n",
    "hyp2 = tf.nn.relu(tf.matmul(hyp1,w2))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([layer2,layer3], stddev = 0.05))\n",
    "hyp3 = tf.nn.relu(tf.matmul(hyp2,w3))\n",
    "w4 = tf.Variable(tf.random.truncated_normal([layer3,layer4],stddev = 0.05))\n",
    "hyp4 = tf.nn.relu(tf.matmul(hyp3,w4))\n",
    "w5 = tf.Variable(tf.random.truncated_normal([layer4,q], stddev = 0.05))\n",
    "hyp5 = tf.matmul(hyp4,w5)\n",
    "###Using softmax to convert the probailities into labels\n",
    "y_pred = tf.nn.softmax(hyp5)\n",
    "###One hot encoding of the predicted labels\n",
    "y_pred_onehot = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.310449\n",
      "2.2854662\n",
      "2.2624664\n",
      "2.239882\n",
      "2.2167156\n",
      "2.192161\n",
      "2.1654642\n",
      "2.1359692\n",
      "2.1030679\n",
      "2.0660846\n",
      "2.0243366\n",
      "1.9770714\n",
      "1.9235904\n",
      "1.8633296\n",
      "1.7959479\n",
      "1.7214513\n",
      "1.6403363\n",
      "1.5537063\n",
      "1.4633801\n",
      "1.3717562\n",
      "1.2814837\n",
      "1.1951182\n",
      "1.1146008\n",
      "1.0411865\n",
      "0.9753254\n",
      "0.91687214\n",
      "0.8653397\n",
      "0.82042676\n",
      "0.7851857\n",
      "0.7961409\n",
      "1.2091218\n",
      "2.822646\n",
      "2.2210927\n",
      "1.5917034\n",
      "1.3192672\n",
      "1.1402625\n",
      "1.0393595\n",
      "0.95345324\n",
      "0.86969036\n",
      "0.79063225\n",
      "0.7238151\n",
      "0.6727612\n",
      "0.6341971\n",
      "0.6037828\n",
      "0.5790223\n",
      "0.5584423\n",
      "0.541618\n",
      "0.52975774\n",
      "0.5337598\n",
      "0.6010096\n",
      "1.0903429\n",
      "1.6292953\n",
      "1.3346775\n",
      "0.7517667\n",
      "0.6253646\n",
      "0.56719625\n",
      "0.53036004\n",
      "0.5069716\n",
      "0.48909616\n",
      "0.47569817\n",
      "0.4648925\n",
      "0.4582683\n",
      "0.45433578\n",
      "0.46008134\n",
      "0.47088376\n",
      "0.51501906\n",
      "0.5514765\n",
      "0.64554673\n",
      "0.59584385\n",
      "0.52985895\n",
      "0.46761146\n",
      "0.43065813\n",
      "0.41422293\n",
      "0.40612966\n",
      "0.4078351\n",
      "0.41328222\n",
      "0.43950674\n",
      "0.46592376\n",
      "0.5477178\n",
      "0.5599703\n",
      "0.59656477\n",
      "0.4934375\n",
      "0.4328306\n",
      "0.39316627\n",
      "0.37050185\n",
      "0.36032966\n",
      "0.35276842\n",
      "0.34764767\n",
      "0.3431319\n",
      "0.33936986\n",
      "0.3358944\n",
      "0.3327841\n",
      "0.32986188\n",
      "0.32718474\n",
      "0.3246468\n",
      "0.32230306\n",
      "0.32009792\n",
      "0.31809375\n",
      "0.31626666\n",
      "0.31469187\n",
      "0.31343347\n",
      "0.31256798\n",
      "0.31243494\n",
      "0.3129931\n",
      "0.31553113\n",
      "0.31928593\n",
      "0.3290241\n",
      "0.33997753\n",
      "0.36979902\n",
      "0.39227512\n",
      "0.46090844\n",
      "0.4462985\n",
      "0.4553868\n",
      "0.36962304\n",
      "0.3259246\n",
      "0.303113\n",
      "0.29536107\n",
      "0.29106182\n",
      "0.28852597\n",
      "0.28641087\n",
      "0.28462684\n",
      "0.282964\n",
      "0.2814778\n",
      "0.2800788\n",
      "0.2788541\n",
      "0.27773756\n",
      "0.27685422\n",
      "0.27615684\n",
      "0.27584186\n",
      "0.27593008\n",
      "0.2767348\n",
      "0.27845424\n",
      "0.28164083\n",
      "0.28706428\n",
      "0.2957163\n",
      "0.3100679\n",
      "0.3307308\n",
      "0.3655352\n",
      "0.40177897\n",
      "0.45263445\n",
      "0.43608397\n",
      "0.395636\n",
      "0.3176904\n",
      "0.28037545\n",
      "0.26529476\n",
      "0.26087505\n",
      "0.25854763\n",
      "0.2567805\n",
      "0.25522164\n",
      "0.2537754\n",
      "0.25241122\n",
      "0.25111264\n",
      "0.24986698\n",
      "0.24866751\n",
      "0.24750814\n",
      "0.24638356\n",
      "0.2452916\n",
      "0.24422903\n",
      "0.24319127\n",
      "0.24217692\n",
      "0.24118395\n",
      "0.24021107\n",
      "0.23925638\n",
      "0.23831841\n",
      "0.23739667\n",
      "0.23648894\n",
      "0.23559503\n",
      "0.23471425\n",
      "0.23384635\n",
      "0.23299089\n",
      "0.2321463\n",
      "0.23131289\n",
      "0.2304898\n",
      "0.22967628\n",
      "0.22887203\n",
      "0.22807659\n",
      "0.2272905\n",
      "0.22651297\n",
      "0.22574401\n",
      "0.22498333\n",
      "0.22423027\n",
      "0.22348528\n",
      "0.22274795\n",
      "0.2220178\n",
      "0.22129525\n",
      "0.22058031\n",
      "0.21987234\n",
      "0.2191725\n",
      "0.2184806\n",
      "0.21779744\n",
      "0.2171237\n",
      "0.21645965\n",
      "0.21580657\n",
      "0.2151661\n",
      "0.21454047\n",
      "0.21393512\n",
      "0.21335398\n",
      "0.21280414\n",
      "0.21229795\n",
      "0.21185255\n",
      "0.21149085\n",
      "0.21125016\n",
      "0.21116605\n",
      "0.21134932\n",
      "0.21185032\n",
      "0.21296477\n",
      "0.2148001\n",
      "0.21814375\n",
      "0.22335261\n",
      "0.23315495\n",
      "0.24986768\n",
      "0.28624648\n",
      "0.3766593\n",
      "0.6795529\n",
      "1.596425\n",
      "1.1126857\n",
      "0.7754237\n",
      "0.38798046\n",
      "0.26513746\n",
      "0.252199\n",
      "0.24438699\n",
      "0.23833495\n",
      "0.23340994\n",
      "0.22930355\n",
      "0.22581957\n",
      "0.2228217\n",
      "0.22021037\n",
      "0.21790263\n",
      "0.21584171\n",
      "0.21397714\n",
      "0.212278\n",
      "0.21071672\n",
      "0.20927426\n",
      "0.20793128\n",
      "0.20667559\n",
      "0.20549199\n",
      "0.20437104\n",
      "0.20330568\n",
      "0.2022903\n",
      "0.20131984\n",
      "0.2003899\n",
      "0.19949427\n",
      "0.19863017\n",
      "0.19779468\n",
      "0.19698526\n",
      "0.1961989\n",
      "0.19543314\n",
      "0.19468595\n",
      "0.19395709\n",
      "0.19324473\n",
      "accuracy 0.9434\n"
     ]
    }
   ],
   "source": [
    "###COST\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = hyp5, labels = y))\n",
    "###Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.12).minimize(cost)\n",
    "\n",
    "###Calculating test accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_onehot, y_onehot), \"float\"))\n",
    "session = tf.Session()\n",
    "### Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "### Run the optimizer\n",
    "def opt():\n",
    "    for i in range(250):\n",
    "        _,cos = session.run([optimizer,cost],feed_dict={x: x_train_flat, y: y_train_onehot})\n",
    "        print(cos)\n",
    "opt()\n",
    "accuracy_org = session.run(accuracy, feed_dict={x: x_test_flat,y_onehot: y_test})\n",
    "print('accuracy', accuracy_org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:307: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:352: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "accuracy 0.9434\n",
      "accuracy 0.9153\n",
      "accuracy 0.7379\n",
      "accuracy 0.666\n",
      "accuracy 0.4842\n",
      "accuracy 0.2179\n",
      "accuracy 0.193\n",
      "accuracy 0.0948\n",
      "accuracy 0.1114\n",
      "accuracy 0.0561\n"
     ]
    }
   ],
   "source": [
    "def neuron_prun():\n",
    "    accuracy_neuprun = []\n",
    "    for sparsity in ([0, 25, 50, 60, 70, 80, 90, 95, 97, 99]):\n",
    "        \n",
    "        ### Load the weights values into a new variable\n",
    "        w1_b = (session.run(w1))\n",
    "        w2_b = (session.run(w2))\n",
    "        w3_b = (session.run(w3))\n",
    "        w4_b = (session.run(w4))\n",
    "        w5_b = (session.run(w5))\n",
    "        \n",
    "        ###Calculating the L2 norm of each feature\n",
    "        w1_norm = tf.linalg.norm(w1_b,axis = 0)\n",
    "        ###Calculating the percentile of the L2 norm vector\n",
    "        w1_per = tf.contrib.distributions.percentile(w1_norm,q = sparsity,axis=None,interpolation=None)\n",
    "        ###Creating a binary mask for the values that are lesser than the percentile. The L2 norm values that are greater percentile values are marked as 1 whereas the remaining values are marked as zero\n",
    "        w1_mask =tf.to_double((tf.greater_equal(w1_norm,w1_per)))\n",
    "        w1_mask = w1_mask.eval(session=sess)\n",
    "        ### Finding the indices of the zero values in the masking array\n",
    "        w1_mask_index = np.where(w1_mask == 0)\n",
    "        w1_mask_index = w1_mask_index[0][:]\n",
    "        w1_a= w1_b\n",
    "        ### The columns corresponding the zero indices of the masking array are equated to zero.\n",
    "        for i in range(len(w1_mask_index)):w1_a[:,w1_mask_index[i]] = 0\n",
    "        ### Convert numpy array to tensor\n",
    "        w1_np = tf.Variable(tf.convert_to_tensor(w1_a))\n",
    "        ###Calculate the hypothesis\n",
    "        ht1 = tf.nn.relu(tf.matmul(x,w1_np))\n",
    "        \n",
    "        ####Repeat the same for the all the weights\n",
    "        \n",
    "        w2_norm = tf.linalg.norm(w2_b,axis = 0)\n",
    "        w2_per = tf.contrib.distributions.percentile(w2_norm,q = sparsity,axis=None,interpolation=None)\n",
    "        w2_mask =tf.to_double((tf.greater_equal(w2_norm,w2_per)))\n",
    "        w2_mask = w2_mask.eval(session=sess)\n",
    "        w2_mask_index = np.where(w2_mask == 0)\n",
    "        w2_mask_index = w2_mask_index[0][:]\n",
    "        w2_a= w2_b\n",
    "        for i in range(len(w2_mask_index)):w2_a[:,w2_mask_index[i]] = 0\n",
    "        w2_np = tf.Variable(tf.convert_to_tensor(w2_a))\n",
    "        ht2 = tf.nn.relu(tf.matmul(ht1,w2_np))\n",
    "\n",
    "        w3_norm = tf.linalg.norm(w3_b,axis = 0)\n",
    "        w3_per = tf.contrib.distributions.percentile(w3_norm,q = sparsity,axis=None,interpolation=None)\n",
    "        w3_mask =tf.to_double((tf.greater_equal(w3_norm,w3_per)))\n",
    "        w3_mask = w3_mask.eval(session=sess)\n",
    "        w3_mask_index = np.where(w3_mask == 0)\n",
    "        w3_mask_index = w3_mask_index[0][:]\n",
    "        w3_a= w3_b\n",
    "        for i in range(len(w3_mask_index)):w3_a[:,w3_mask_index[i]] = 0\n",
    "        w3_np = tf.Variable(tf.convert_to_tensor(w3_a))\n",
    "        ht3 = tf.nn.relu(tf.matmul(ht2,w3_np))\n",
    "\n",
    "        w4_norm = tf.linalg.norm(w4_b,axis = 0)\n",
    "        w4_per = tf.contrib.distributions.percentile(w4_norm,q = sparsity,axis=None,interpolation=None)\n",
    "        w4_mask =tf.to_double((tf.greater_equal(w4_norm,w4_per)))\n",
    "        w4_mask = w4_mask.eval(session=sess)\n",
    "        w4_mask_index = np.where(w4_mask == 0)\n",
    "        w4_mask_index = w4_mask_index[0][:]\n",
    "        w4_a= w4_b\n",
    "        for i in range(len(w4_mask_index)):w4_a[:,w4_mask_index[i]] = 0\n",
    "        w4_np = tf.Variable(tf.convert_to_tensor(w4_a))\n",
    "        ht4 = tf.nn.relu(tf.matmul(ht3,w4_np))\n",
    "\n",
    "        w5_b = tf.Variable(tf.convert_to_tensor(w5_b))\n",
    "        ht5 = tf.matmul(ht4,w5_b)\n",
    "        ###Using softmax to convert the probailities into labels\n",
    "        y_pred = tf.nn.softmax(ht5)\n",
    "        ###One hot encoding of the predicted labels\n",
    "        y_pred_onehot3 = tf.argmax(y_pred, axis=1)\n",
    "        accuracy_wn = tf.reduce_mean(tf.cast(tf.equal(y_pred_onehot3, y_onehot), \"float\"))\n",
    "        ###Initialize the new weights\n",
    "        session.run(w1_np.initializer)\n",
    "        session.run(w2_np.initializer)\n",
    "        session.run(w3_np.initializer)\n",
    "        session.run(w4_np.initializer)\n",
    "        session.run(w5_b.initializer)\n",
    "        ###Calculate the accuracy using the updated weights\n",
    "        np_accuracy = session.run(accuracy_wn, feed_dict={x: x_test_flat,y_onehot: y_test})\n",
    "        accuracy_neuprun.append(np_accuracy)\n",
    "        print('accuracy', np_accuracy)\n",
    "    return accuracy_neuprun\n",
    "ac_neuron = neuron_prun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiply all the accuracy value with 100\n",
    "neuron_accuracy = [i * 100 for i in ac_neuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9434\n",
      "accuracy 0.9434\n",
      "accuracy 0.9433\n",
      "accuracy 0.9429\n",
      "accuracy 0.9399\n",
      "accuracy 0.93\n",
      "accuracy 0.6861\n",
      "accuracy 0.2032\n",
      "accuracy 0.0957\n",
      "accuracy 0.0906\n"
     ]
    }
   ],
   "source": [
    "def weig_prun():\n",
    "    accuracy_weightprun = []\n",
    "    for sparsity in ([0, 25, 50, 60, 70, 80, 90, 95, 97, 99]):\n",
    "    #Weight pruning\n",
    "    ### Load the weights values into a new variable\n",
    "        pru_w1 = (session.run(w1))\n",
    "        pru_w2 = (session.run(w2))\n",
    "        pru_w3 = (session.run(w3))\n",
    "        pru_w4 = (session.run(w4))\n",
    "        pru_w5 = (session.run(w5))\n",
    "        ###Flattening the weight array using reshape command\n",
    "        pru_w1=tf.reshape(pru_w1,[pru_w1.shape[0]*pru_w1.shape[1]])\n",
    "        pru_w2=tf.reshape(pru_w2,[pru_w2.shape[0]*pru_w2.shape[1]])\n",
    "        pru_w3=tf.reshape(pru_w3,[pru_w3.shape[0]*pru_w3.shape[1]])\n",
    "        pru_w4=tf.reshape(pru_w4,[pru_w4.shape[0]*pru_w4.shape[1]])\n",
    "        \n",
    "        \n",
    "        ###Calculating the percentile of the flattened weight vector\n",
    "        y_p = tf.contrib.distributions.percentile(pru_w1,q = sparsity,axis=None,interpolation=None)\n",
    "        ### Craete a binary mask for the condition such that all values greater than the percentile is equated to one while the values lesser than the percentile is equated to zero\n",
    "        pru_w1_abs_mask = tf.cast(tf.to_int32(tf.abs(pru_w1) > y_p), tf.float32)\n",
    "        ###Element wise multiplication of weight vector and mask vector to convert all the weights whose values is less than the percentile to zero\n",
    "        pru_w1 = np.multiply(pru_w1.eval(session=session),pru_w1_abs_mask.eval(session=session))\n",
    "        ### Convert the resulting the weight vector into tensor and reshape it into appropriate size\n",
    "        pru_w1 = tf.Variable(tf.convert_to_tensor(pru_w1.reshape([m,layer1])))\n",
    "        ###Calculate the hypothesis\n",
    "        ht1 = tf.nn.relu(tf.matmul(x,pru_w1))\n",
    "\n",
    "         ####Repeat the same for the all the weights\n",
    "        \n",
    "        y_p2 = tf.contrib.distributions.percentile(pru_w2,q = sparsity,axis=None,interpolation=None)\n",
    "        pru_w2_abs_mask = tf.cast(tf.to_int32(tf.abs(pru_w2) > y_p2), tf.float32)\n",
    "        pru_w2 = np.multiply(pru_w2.eval(session=session),pru_w2_abs_mask.eval(session=session))\n",
    "        pru_w2 = tf.Variable(tf.convert_to_tensor(pru_w2.reshape([layer1,layer2])))\n",
    "        ht2 = tf.nn.relu(tf.matmul(ht1,pru_w2))\n",
    "\n",
    "        y_p3 = tf.contrib.distributions.percentile(pru_w3,q = sparsity,axis=None,interpolation=None)\n",
    "        pru_w3_abs_mask = tf.cast(tf.to_int32(tf.abs(pru_w3) > y_p3), tf.float32)\n",
    "        pru_w3 = np.multiply(pru_w3.eval(session=session),pru_w3_abs_mask.eval(session=session))\n",
    "        pru_w3 = tf.Variable(tf.convert_to_tensor(pru_w3.reshape([layer2,layer3])))\n",
    "        ht3 = tf.nn.relu(tf.matmul(ht2,pru_w3))\n",
    "\n",
    "        y_p4 = tf.contrib.distributions.percentile(pru_w4,q = sparsity,axis=None,interpolation=None)\n",
    "        pru_w4_abs_mask = tf.cast(tf.to_int32(tf.abs(pru_w4) > y_p4), tf.float32)\n",
    "        pru_w4 = np.multiply(pru_w4.eval(session=session),pru_w4_abs_mask.eval(session=session))\n",
    "        pru_w4 = tf.Variable(tf.convert_to_tensor(pru_w4.reshape([layer3,layer4])))\n",
    "        ht4 = tf.nn.relu(tf.matmul(ht3,pru_w4))\n",
    "\n",
    "        pru_w5 = tf.Variable(tf.convert_to_tensor(pru_w5))\n",
    "        ht5 = tf.nn.relu(tf.matmul(ht4,pru_w5))\n",
    "        ###Using softmax to convert the probailities into labels\n",
    "        y_pred2 = tf.nn.softmax(ht5)\n",
    "        ###One hot encoding of the predicted labels\n",
    "        y_pred_onehot2 = tf.argmax(y_pred2, axis=1)\n",
    "        accuracy_w = tf.reduce_mean(tf.cast(tf.equal(y_pred_onehot2, y_onehot), \"float\"))\n",
    "        ###Initialize the new weights\n",
    "        session.run(pru_w1.initializer)\n",
    "        session.run(pru_w2.initializer)\n",
    "        session.run(pru_w3.initializer)\n",
    "        session.run(pru_w4.initializer)\n",
    "        session.run(pru_w5.initializer)\n",
    "        ###Calculate the accuracy using the updated weights\n",
    "        wg_accuracy = session.run(accuracy_w, feed_dict={x: x_test_flat,y_onehot: y_test})\n",
    "        accuracy_weightprun.append(wg_accuracy)\n",
    "        print('accuracy', wg_accuracy)\n",
    "    return accuracy_weightprun\n",
    "ac_weight = weig_prun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiply all the accuracy value with 100\n",
    "weight_accuracy = [i * 100 for i in ac_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = [0, 25, 50, 60, 70, 80, 90, 95, 97, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce0713a6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Plotting the accuracy of both weight and neuron pruning against the percentage of sparsity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sparsity,weight_accuracy,label= 'Weight Pruning');\n",
    "plt.plot(sparsity,neuron_accuracy,label='Neuron Pruning');\n",
    "plt.title(\"Sparsity Percentage vs Accuracy\")\n",
    "plt.xlabel(\"Sparsity Percentage\")\n",
    "plt.ylabel(\"Accuracy\");\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame()\n",
    "r['Sparsity Percentage'] = sparsity\n",
    "r['Weight Pruning Accuracy'] = weight_accuracy\n",
    "r['Neuron Pruning Accuracy'] = neuron_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparsity Percentage</th>\n",
       "      <th>Weight Pruning Accuracy</th>\n",
       "      <th>Neuron Pruning Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.340003</td>\n",
       "      <td>94.340003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>94.340003</td>\n",
       "      <td>91.530001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>94.330001</td>\n",
       "      <td>73.790002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>94.290000</td>\n",
       "      <td>66.600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>93.989998</td>\n",
       "      <td>48.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80</td>\n",
       "      <td>93.000001</td>\n",
       "      <td>21.789999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90</td>\n",
       "      <td>68.610001</td>\n",
       "      <td>19.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>20.320000</td>\n",
       "      <td>9.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>11.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>5.610000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sparsity Percentage           ...             Neuron Pruning Accuracy\n",
       "0                    0           ...                           94.340003\n",
       "1                   25           ...                           91.530001\n",
       "2                   50           ...                           73.790002\n",
       "3                   60           ...                           66.600001\n",
       "4                   70           ...                           48.420000\n",
       "5                   80           ...                           21.789999\n",
       "6                   90           ...                           19.300000\n",
       "7                   95           ...                            9.480000\n",
       "8                   97           ...                           11.140000\n",
       "9                   99           ...                            5.610000\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
